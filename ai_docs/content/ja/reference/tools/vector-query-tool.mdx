---
title: "リファレンス: createVectorQueryTool() | RAG | Mastra Tools ドキュメント"
description: フィルタリングやリランキングに対応し、ベクトルストア上でのセマンティック検索を可能にする Mastra の Vector Query Tool のドキュメント。
---

import { Callout } from "nextra/components";
import { Tabs } from "nextra/components";


# createVectorQueryTool()

`createVectorQueryTool()` 関数は、ベクターストア上でセマンティック検索を行うためのツールを作成します。フィルタリング、再ランキング、データベース固有の設定をサポートし、さまざまなベクターストアのバックエンドと統合できます。

## 基本的な使用方法

```typescript
import { openai } from "@ai-sdk/openai";
import { createVectorQueryTool } from "@mastra/rag";

const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
});
```

## パラメータ

<Callout>
  **パラメータ要件:** ほとんどのフィールドは作成時にデフォルトとして設定できます。
  一部のフィールドはランタイムコンテキストまたは入力によって実行時に上書きできます。
  必須フィールドが作成時にも実行時にも指定されていない場合はエラーになります。なお、`model`、`id`、`description` は作成時にのみ設定可能です。
</Callout>

<PropertiesTable
  content={[
    {
      name: "id",
      type: "string",
      description:
        "ツールのカスタム ID。デフォルト: 'VectorQuery {vectorStoreName} {indexName} Tool'。（作成時のみ設定可能）",
      isOptional: true,
    },
    {
      name: "description",
      type: "string",
      description:
        "ツールのカスタム説明。デフォルト: 'Access the knowledge base to find information needed to answer user questions'（作成時のみ設定可能）",
      isOptional: true,
    },
    {
      name: "model",
      type: "EmbeddingModel",
      description:
        "ベクトル検索に使用する埋め込みモデル。（作成時のみ設定可能）",
      isOptional: false,
    },
    {
      name: "vectorStoreName",
      type: "string",
      description:
        "クエリ対象のベクトルストア名。（作成時に設定、または実行時に上書き可能）",
      isOptional: false,
    },
    {
      name: "indexName",
      type: "string",
      description:
        "ベクトルストア内のインデックス名。（作成時に設定、または実行時に上書き可能）",
      isOptional: false,
    },
    {
      name: "enableFilter",
      type: "boolean",
      description:
        "メタデータに基づく結果のフィルタリングを有効化します。（作成時のみ設定可能ですが、実行時コンテキストでフィルタが指定された場合は自動的に有効になります）",
      isOptional: true,
      defaultValue: "false",
    },
    {
      name: "includeVectors",
      type: "boolean",
      description:
        "結果に埋め込みベクトルを含めます。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
      defaultValue: "false",
    },
    {
      name: "includeSources",
      type: "boolean",
      description:
        "結果に完全なリトリーバルオブジェクトを含めます。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
      defaultValue: "true",
    },
    {
      name: "reranker",
      type: "RerankConfig",
      description:
        "結果のリランキング用オプション。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
    },
    {
      name: "databaseConfig",
      type: "DatabaseConfig",
      description:
        "クエリ最適化のためのデータベース固有の設定。（作成時に設定、または実行時に上書き可能）",
      isOptional: true,
    },
    {
      name: "providerOptions",
      type: "Record<string, Record<string, any>>",
      description:
        "埋め込みモデルのプロバイダ固有オプション（例: outputDimensionality）。**重要**: AI SDK の EmbeddingModel V2 にのみ対応します。V1 モデルでは、モデル作成時にオプションを設定してください。",
      isOptional: true,
    },
  ]}
/>

### DatabaseConfig

`DatabaseConfig` 型では、クエリ操作に自動的に適用されるデータベース固有の設定を指定できます。これにより、各種ベクターストアが提供する固有の機能や最適化を活用できます。

<PropertiesTable
  content={[
    {
      name: "pinecone",
      type: "PineconeConfig",
      description: "Pinecone ベクターストア向けの設定",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "namespace",
              description: "ベクトルを整理するための Pinecone のネームスペース",
              isOptional: true,
              type: "string",
            },
            {
              name: "sparseVector",
              description: "ハイブリッド検索用のスパースベクトル",
              isOptional: true,
              type: "{ indices: number[]; values: number[]; }",
            },
          ],
        },
      ],
    },
    {
      name: "pgvector",
      type: "PgVectorConfig",
      description: "pgvector 拡張機能を使用する PostgreSQL 向けの設定",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "minScore",
              description: "結果の最小類似度スコアのしきい値",
              isOptional: true,
              type: "number",
            },
            {
              name: "ef",
              description: "HNSW の検索パラメータ — 精度と速度のトレードオフを制御",
              isOptional: true,
              type: "number",
            },
            {
              name: "probes",
              description: "IVFFlat のプローブ数パラメータ — 検索時に訪問するセル数",
              isOptional: true,
              type: "number",
            },
          ],
        },
      ],
    },
    {
      name: "chroma",
      type: "ChromaConfig",
      description: "Chroma ベクターストア向けの設定",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "where",
              description: "メタデータのフィルタ条件",
              isOptional: true,
              type: "Record<string, any>",
            },
            {
              name: "whereDocument",
              description: "ドキュメント内容のフィルタ条件",
              isOptional: true,
              type: "Record<string, any>",
            },
          ],
        },
      ],
    },
  ]}
/>

### RerankConfig

<PropertiesTable
  content={[
    {
      name: "model",
      type: "MastraLanguageModel",
      description: "リランキングに用いる言語モデル",
      isOptional: false,
    },
    {
      name: "options",
      type: "RerankerOptions",
      description: "リランキング処理のオプション",
      isOptional: true,
      properties: [
        {
          type: "object",
          parameters: [
            {
              name: "weights",
              description:
                "スコアリング要素の重み（semantic: 0.4、vector: 0.4、position: 0.2）",
              isOptional: true,
              type: "WeightConfig",
            },
            {
              name: "topK",
              description: "返す上位候補の件数",
              isOptional: true,
              type: "number",
              defaultValue: "3",
            },
          ],
        },
      ],
    },
  ]}
/>

## 返り値

このツールは次のオブジェクトを返します：

<PropertiesTable
  content={[
    {
      name: "relevantContext",
      type: "string",
      description: "最も関連性の高いドキュメントのチャンクから結合されたテキスト",
    },
    {
      name: "sources",
      type: "QueryResult[]",
      description:
        "完全な取得結果オブジェクトの配列。各オブジェクトには、元のドキュメント、チャンク、類似度スコアを参照するために必要な情報がすべて含まれます。",
    },
  ]}
/>

### QueryResult オブジェクトの構造

```typescript
{
  id: string;         // 一意のチャンク／ドキュメント識別子
  metadata: any;      // メタデータの全フィールド（ドキュメントIDなど）
  vector: number[];   // 埋め込みベクトル（利用可能な場合）
  score: number;      // この検索での類似度スコア
  document: string;   // チャンク／ドキュメントの全文（利用可能な場合）
}
```

## デフォルトのツール説明

デフォルトの説明は次の点に重点を置いています：

- 保存済みの知識から関連情報を見つけること
- ユーザーの質問に回答すること
- 事実に基づくコンテンツを取得すること

## 結果の処理

ツールはユーザーのクエリに応じて返す結果数を決定し、既定では10件を返します。必要に応じてクエリの要件に合わせて調整できます。

## フィルタ付きの例

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  enableFilter: true,
});
```

フィルタを有効にすると、このツールはクエリを処理し、セマンティック検索と組み合わせるメタデータフィルタを構築します。処理は次のように進みます。

1. ユーザーが「'version' フィールドが 2.0 より大きいコンテンツを見つけて」のように、特定のフィルタ要件を含むクエリを行う
2. エージェントがクエリを解析し、適切なフィルタを構築する:
   ```typescript
   {
      "version": { "$gt": 2.0 }
   }
   ```

このエージェント主導のアプローチでは、次のことを行います:

- 自然言語のクエリをフィルタ仕様に変換
- ベクターストア固有のフィルタ構文を実装
- クエリ用語をフィルタ演算子に対応付け

フィルタ構文の詳細やストア固有の機能については、[Metadata Filters](../rag/metadata-filters) のドキュメントを参照してください。

エージェント主導のフィルタリングの例については、[Agent-Driven Metadata Filtering](../../../examples/rag/usage/filter-rag.mdx) を参照してください。

## リランクの例

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "milvus",
  indexName: "documentation",
  model: openai.embedding("text-embedding-3-small"),
  reranker: {
    model: openai("gpt-4o-mini"),
    options: {
      weights: {
        semantic: 0.5, // セマンティック関連度の重み
        vector: 0.3, // ベクトル類似度の重み
        position: 0.2, // 元の順位の重み
      },
      topK: 5,
    },
  },
});
```

リランクは次の要素を組み合わせて結果の品質を高めます:

- セマンティック関連度: LLM によるテキスト類似度のスコアリング
- ベクトル類似度: 元のベクトル距離スコア
- 位置バイアス: 元の結果の並び順の考慮
- クエリ分析: クエリ特性に基づく調整

リランカーは初期のベクトル検索結果を処理し、関連性を最適化した並べ替え済みリストを返します。

## カスタム説明の例

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  description:
    "会社のポリシーや手順に関する質問に答えるため、関連情報を見つけられるよう文書アーカイブを検索します",
});
```

この例では、情報検索という本来の目的を保ちつつ、特定のユースケースに合わせてツールの説明をカスタマイズする方法を示しています。

## データベース固有の構成例

`databaseConfig` パラメータを使うと、各ベクトルデータベース特有の機能や最適化を活用できます。これらの設定はクエリ実行時に自動で適用されます。

<Tabs items={['Pinecone', 'pgVector', 'Chroma', 'Multiple Configs']}>
  <Tabs.Tab>
    ### Pinecone の構成

    ```typescript
    const pineconeQueryTool = createVectorQueryTool({
      vectorStoreName: "pinecone",
      indexName: "docs",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        pinecone: {
          namespace: "production",  // 環境ごとにベクトルを整理
          sparseVector: {           // ハイブリッド検索を有効化
            indices: [0, 1, 2, 3],
            values: [0.1, 0.2, 0.15, 0.05]
          }
        }
      }
    });
    ```

    **Pinecone の特長:**
    - **Namespace**: 同一インデックス内でデータセットを分離
    - **Sparse Vector**: 密・疎埋め込みを組み合わせて検索品質を向上
    - **ユースケース**: マルチテナントアプリ、ハイブリッド意味検索
  </Tabs.Tab>

  <Tabs.Tab>
    ### pgVector の構成

    ```typescript
    const pgVectorQueryTool = createVectorQueryTool({
      vectorStoreName: "postgres",
      indexName: "embeddings",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        pgvector: {
          minScore: 0.7,    // 類似度が70%を超える結果のみ返す
          ef: 200,          // 大きいほど精度向上、検索は低速化
          probes: 10        // IVFFlatの場合: probesが多いほど再現率向上
        }
      }
    });
    ```

    **pgVector の特長:**
    - **minScore**: 低品質な一致を除外
    - **ef (HNSW)**: HNSWインデックスで精度と速度のバランスを調整
    - **probes (IVFFlat)**: IVFFlatインデックスで再現率と速度のバランスを調整
    - **ユースケース**: パフォーマンス調整、品質フィルタリング
  </Tabs.Tab>

  <Tabs.Tab>
    ### Chroma の構成

    ```typescript
    const chromaQueryTool = createVectorQueryTool({
      vectorStoreName: "chroma",
      indexName: "documents",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        chroma: {
          where: {                    // メタデータでフィルタリング
            "category": "technical",
            "status": "published"
          },
          whereDocument: {            // ドキュメント内容でフィルタリング
            "$contains": "API"
          }
        }
      }
    });
    ```

    **Chroma の特長:**
    - **where**: メタデータフィールドでフィルタ
    - **whereDocument**: ドキュメント内容でフィルタ
    - **ユースケース**: 高度なフィルタリング、内容ベース検索
  </Tabs.Tab>

  <Tabs.Tab>
    ### 複数データベースの構成

    ```typescript
    // 複数のデータベース向けに構成（動的ストアに便利）
    const multiDbQueryTool = createVectorQueryTool({
      vectorStoreName: "dynamic-store", // 実行時に設定
      indexName: "docs",
      model: openai.embedding("text-embedding-3-small"),
      databaseConfig: {
        pinecone: {
          namespace: "default"
        },
        pgvector: {
          minScore: 0.8,
          ef: 150
        },
        chroma: {
          where: { "type": "documentation" }
        }
      }
    });
    ```

    **マルチ構成の利点:**
    - 1つのツールで複数のベクトルストアに対応
    - データベース固有の最適化が自動適用
    - 柔軟なデプロイシナリオ
  </Tabs.Tab>
</Tabs>

### ランタイム設定のオーバーライド

さまざまなシナリオに対応するため、実行時にデータベース設定を上書きできます:

```typescript
import { RuntimeContext } from '@mastra/core/runtime-context';

const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
  databaseConfig: {
    pinecone: {
      namespace: "development"
    }
  }
});

// 実行時にオーバーライド
const runtimeContext = new RuntimeContext();
runtimeContext.set('databaseConfig', {
  pinecone: {
    namespace: 'production'  // 本番用のネームスペースに切り替え
  }
});

const response = await agent.generate(
  "Find information about deployment",
  { runtimeContext }
);
```

この方法により、次のことが可能になります:

- 環境（dev/staging/prod）の切り替え
- 負荷に応じたパフォーマンスパラメータの調整
- リクエスト単位で異なるフィルタリング戦略の適用

## 例: ランタイムコンテキストの使用

```typescript
const queryTool = createVectorQueryTool({
  vectorStoreName: "pinecone",
  indexName: "docs",
  model: openai.embedding("text-embedding-3-small"),
});
```

ランタイムコンテキストを使う場合は、実行時にランタイムコンテキスト経由で必要なパラメータを指定します:

```typescript
const runtimeContext = new RuntimeContext<{
  vectorStoreName: string;
  indexName: string;
  topK: number;
  filter: VectorFilter;
  databaseConfig: DatabaseConfig;
}>();
runtimeContext.set("vectorStoreName", "my-store");
runtimeContext.set("indexName", "my-index");
runtimeContext.set("topK", 5);
runtimeContext.set("filter", { category: "docs" });
runtimeContext.set("databaseConfig", {
  pinecone: { namespace: "runtime-namespace" }
});
runtimeContext.set("model", openai.embedding("text-embedding-3-small"));

const response = await agent.generate(
  "Find documentation from the knowledge base.",
  {
    runtimeContext,
  },
);
```

ランタイムコンテキストの詳細は以下を参照してください:

- [Agent Runtime Context](../../docs/agents/runtime-context.mdx)
- [Tool Runtime Context](../../docs/tools-mcp/runtime-context.mdx)

## Mastra Server なしでの使用

このツールは単体で、クエリに一致するドキュメントを取得できます:

```typescript copy showLineNumbers filename="src/index.ts"
import { openai } from "@ai-sdk/openai";
import { RuntimeContext } from "@mastra/core/runtime-context";
import { createVectorQueryTool } from "@mastra/rag";
import { PgVector } from "@mastra/pg";

const pgVector = new PgVector({
  connectionString: process.env.POSTGRES_CONNECTION_STRING!,
});

const vectorQueryTool = createVectorQueryTool({
  vectorStoreName: "pgVector", // ストアを渡しているので省略可
  vectorStore: pgVector,
  indexName: "embeddings",
  model: openai.embedding("text-embedding-3-small"),
});

const runtimeContext = new RuntimeContext();
const queryResult = await vectorQueryTool.execute({
  context: { queryText: "foo", topK: 1 },
  runtimeContext,
});

console.log(queryResult.sources);
```

## ツールの詳細

このツールは次の要素で構成されています:

- **ID**: `VectorQuery {vectorStoreName} {indexName} Tool`
- **入力スキーマ**: queryText と filter オブジェクトが必要
- **出力スキーマ**: relevantContext 文字列を返す

## 関連項目

- [rerank()](../rag/rerank)
- [createGraphRAGTool](./graph-rag-tool)