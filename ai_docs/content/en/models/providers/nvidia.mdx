---
title: "Nvidia | Models | Mastra"
description: "Use Nvidia models with Mastra. 13 models available."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}
{/* Generated at: 2025-10-07T21:22:00.018Z */}

import { ProviderModelsTable } from "@/components/provider-models-table";
import { Callout } from "nextra/components";


# <img src="https://models.dev/logos/nvidia.svg" alt="Nvidia logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />Nvidia

Access 13 Nvidia models through Mastra's model router. Authentication is handled automatically using the `NVIDIA_API_KEY` environment variable.

Learn more in the [Nvidia documentation](https://docs.api.nvidia.com/nim/).

```bash
NVIDIA_API_KEY=your-api-key
```

```typescript
import { Agent } from "@mastra/core";

const agent = new Agent({
  name: "my-agent",
  instructions: "You are a helpful assistant",
  model: "nvidia/black-forest-labs/flux.1-dev"
});

// Generate a response
const response = await agent.generate("Hello!");

// Stream a response
const stream = await agent.stream("Tell me a story");
for await (const chunk of stream) {
  console.log(chunk);
}
```

<Callout type="info">
Mastra uses the OpenAI-compatible `/chat/completions` endpoint. Some provider-specific features may not be available. Check the [Nvidia documentation](https://docs.api.nvidia.com/nim/) for details.
</Callout>

## Models

<ProviderModelsTable 
  models={[
  {
    "model": "nvidia/moonshotai/kimi-k2-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/cosmos-nemotron-34b",
    "imageInput": true,
    "audioInput": false,
    "videoInput": true,
    "toolUsage": false,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/parakeet-tdt-0.6b-v2",
    "imageInput": false,
    "audioInput": true,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": null,
    "maxOutput": 4096,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/nemoretriever-ocr-v1",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": null,
    "maxOutput": 4096,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/nvidia/llama-3.1-nemotron-ultra-253b-v1",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/google/gemma-3-27b-it",
    "imageInput": true,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/microsoft/phi-4-mini-instruct",
    "imageInput": true,
    "audioInput": true,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/openai/whisper-large-v3",
    "imageInput": false,
    "audioInput": true,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": null,
    "maxOutput": 4096,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/openai/gpt-oss-120b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/qwen/qwen3-235b-a22b",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 131072,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/qwen/qwen3-coder-480b-a35b-instruct",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": false,
    "contextWindow": 262144,
    "maxOutput": 66536,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/deepseek-ai/deepseek-v3.1",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": true,
    "reasoning": true,
    "contextWindow": 128000,
    "maxOutput": 8192,
    "inputCost": null,
    "outputCost": null
  },
  {
    "model": "nvidia/black-forest-labs/flux.1-dev",
    "imageInput": false,
    "audioInput": false,
    "videoInput": false,
    "toolUsage": false,
    "reasoning": false,
    "contextWindow": 4096,
    "maxOutput": null,
    "inputCost": null,
    "outputCost": null
  }
]}
/>

## Advanced Configuration

### Custom Headers

```typescript
const agent = new Agent({
  name: "custom-agent",
  model: {
    url: "https://integrate.api.nvidia.com/v1",
    modelId: "black-forest-labs/flux.1-dev",
    apiKey: process.env.NVIDIA_API_KEY,
    headers: {
      "X-Custom-Header": "value"
    }
  }
});
```

### Dynamic Model Selection

```typescript
const agent = new Agent({
  name: "dynamic-agent",
  model: ({ runtimeContext }) => {
    const useAdvanced = runtimeContext.task === "complex";
    return useAdvanced 
      ? "nvidia/qwen/qwen3-coder-480b-a35b-instruct"
      : "nvidia/black-forest-labs/flux.1-dev";
  }
});
```
