---
title: "Vercel | Models | Mastra"  
description: "Use AI models through Vercel."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}
{/* Generated at: 2025-10-07T21:22:00.473Z */}

import { Callout } from "nextra/components";

# <img src="https://models.dev/logos/vercel.svg" alt="Vercel logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />Vercel

Vercel aggregates models from multiple providers with enhanced features like rate limiting and failover. Access 63 models through Mastra's model router.

Learn more in the [Vercel documentation](https://ai-sdk.dev/providers/ai-sdk-providers).

## Usage

```typescript
import { Agent } from "@mastra/core";

const agent = new Agent({
  name: "my-agent",
  instructions: "You are a helpful assistant",
  model: "vercel/amazon/nova-lite"
});
```

<Callout type="info">
Mastra uses the OpenAI-compatible `/chat/completions` endpoint. Some provider-specific features may not be available. Check the [Vercel documentation](https://ai-sdk.dev/providers/ai-sdk-providers) for details.
</Callout>

## Configuration

```bash
# Use gateway API key
VERCEL_API_KEY=your-gateway-key

# Or use provider API keys directly  
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=ant-...
```


## Available Models

| Model |
|-------|
| `amazon/nova-lite` |
| `amazon/nova-micro` |
| `amazon/nova-pro` |
| `anthropic/claude-3-5-haiku` |
| `anthropic/claude-3-haiku` |
| `anthropic/claude-3-opus` |
| `anthropic/claude-3.5-sonnet` |
| `anthropic/claude-3.7-sonnet` |
| `anthropic/claude-4-1-opus` |
| `anthropic/claude-4-opus` |
| `anthropic/claude-4-sonnet` |
| `anthropic/claude-4.5-sonnet` |
| `cerebras/qwen3-coder` |
| `deepseek/deepseek-r1` |
| `deepseek/deepseek-r1-distill-llama-70b` |
| `google/gemini-2.0-flash` |
| `google/gemini-2.0-flash-lite` |
| `google/gemini-2.5-flash` |
| `google/gemini-2.5-pro` |
| `meta/llama-3.3-70b` |
| `meta/llama-4-maverick` |
| `meta/llama-4-scout` |
| `mistral/codestral` |
| `mistral/magistral-medium` |
| `mistral/magistral-small` |
| `mistral/ministral-3b` |
| `mistral/ministral-8b` |
| `mistral/mistral-large` |
| `mistral/mistral-small` |
| `mistral/mixtral-8x22b-instruct` |
| `mistral/pixtral-12b` |
| `mistral/pixtral-large` |
| `moonshotai/kimi-k2` |
| `morph/morph-v3-fast` |
| `morph/morph-v3-large` |
| `openai/gpt-4-turbo` |
| `openai/gpt-4.1` |
| `openai/gpt-4.1-mini` |
| `openai/gpt-4.1-nano` |
| `openai/gpt-4o` |
| `openai/gpt-4o-mini` |
| `openai/gpt-5` |
| `openai/gpt-5-codex` |
| `openai/gpt-5-mini` |
| `openai/gpt-5-nano` |
| `openai/gpt-oss-120b` |
| `openai/gpt-oss-20b` |
| `openai/o1` |
| `openai/o3` |
| `openai/o3-mini` |
| `openai/o4-mini` |
| `vercel/v0-1.0-md` |
| `vercel/v0-1.5-md` |
| `xai/grok-2` |
| `xai/grok-2-vision` |
| `xai/grok-3` |
| `xai/grok-3-fast` |
| `xai/grok-3-mini` |
| `xai/grok-3-mini-fast` |
| `xai/grok-4` |
| `xai/grok-4-fast` |
| `xai/grok-4-fast-non-reasoning` |
| `xai/grok-code-fast-1` |

