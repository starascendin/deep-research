---
title: "Groq | Models | Mastra"  
description: "Use AI models through Groq."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}
{/* Generated at: 2025-10-07T21:22:00.473Z */}

import { Callout } from "nextra/components";

# <img src="https://models.dev/logos/groq.svg" alt="Groq logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />Groq

Groq aggregates models from multiple providers with enhanced features like rate limiting and failover. Access 17 models through Mastra's model router.

Learn more in the [Groq documentation](https://console.groq.com/docs/models).

## Usage

```typescript
import { Agent } from "@mastra/core";

const agent = new Agent({
  name: "my-agent",
  instructions: "You are a helpful assistant",
  model: "groq/deepseek-r1-distill-llama-70b"
});
```

<Callout type="info">
Mastra uses the OpenAI-compatible `/chat/completions` endpoint. Some provider-specific features may not be available. Check the [Groq documentation](https://console.groq.com/docs/models) for details.
</Callout>

## Configuration

```bash
# Use gateway API key
GROQ_API_KEY=your-gateway-key

# Or use provider API keys directly  
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=ant-...
```


## Available Models

| Model |
|-------|
| `deepseek-r1-distill-llama-70b` |
| `gemma2-9b-it` |
| `llama-3.1-8b-instant` |
| `llama-3.3-70b-versatile` |
| `llama-guard-3-8b` |
| `llama3-70b-8192` |
| `llama3-8b-8192` |
| `meta-llama/llama-4-maverick-17b-128e-instruct` |
| `meta-llama/llama-4-scout-17b-16e-instruct` |
| `meta-llama/llama-guard-4-12b` |
| `mistral-saba-24b` |
| `moonshotai/kimi-k2-instruct` |
| `moonshotai/kimi-k2-instruct-0905` |
| `openai/gpt-oss-120b` |
| `openai/gpt-oss-20b` |
| `qwen-qwq-32b` |
| `qwen/qwen3-32b` |

