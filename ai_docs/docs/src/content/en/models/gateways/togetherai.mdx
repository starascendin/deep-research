---
title: "Together AI | Models | Mastra"  
description: "Use AI models through Together AI."
---

{/* This file is auto-generated by generate-model-docs.ts - DO NOT EDIT MANUALLY */}
{/* Generated at: 2025-10-07T21:22:00.474Z */}

import { Callout } from "nextra/components";

# <img src="https://models.dev/logos/togetherai.svg" alt="Together AI logo" className="inline w-8 h-8 mr-2 align-middle dark:invert dark:brightness-0 dark:contrast-200" />Together AI

Together AI aggregates models from multiple providers with enhanced features like rate limiting and failover. Access 6 models through Mastra's model router.

Learn more in the [Together AI documentation](https://docs.together.ai/docs/serverless-models).

## Usage

```typescript
import { Agent } from "@mastra/core";

const agent = new Agent({
  name: "my-agent",
  instructions: "You are a helpful assistant",
  model: "togetherai/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8"
});
```

<Callout type="info">
Mastra uses the OpenAI-compatible `/chat/completions` endpoint. Some provider-specific features may not be available. Check the [Together AI documentation](https://docs.together.ai/docs/serverless-models) for details.
</Callout>

## Configuration

```bash
# Use gateway API key
TOGETHERAI_API_KEY=your-gateway-key

# Or use provider API keys directly  
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=ant-...
```


## Available Models

| Model |
|-------|
| `Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8` |
| `deepseek-ai/DeepSeek-R1` |
| `deepseek-ai/DeepSeek-V3` |
| `meta-llama/Llama-3.3-70B-Instruct-Turbo` |
| `moonshotai/Kimi-K2-Instruct` |
| `openai/gpt-oss-120b` |

